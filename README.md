# AI-ML-Security---Red-Teaming-Malicious-ONNX-DDOS-Hidden-Payload-
Proof-of-concept ONNX exploit demonstrating how base64-obfuscated Python payloads embedded in model metadata can trigger file cloning and resource exhaustion â€” simulating a stealthy DDoS attack vector in ML pipelines.

# ğŸ“¦ What is ONNX?
ONNX (Open Neural Network Exchange) is a widely adopted format that allows interoperability between different machine learning frameworks. ONNX models are composed of computation graphs, weights, and optional metadata fields (metadata_props), which can be used to store additional information like author, version, or tags.

However, these metadata fields are unregulated and can be misused to embed arbitrary, obfuscated Python code â€” turning a legitimate model into a vector for resource-based attacks.

# ğŸš¨ Exploit Overview: Metadata-Based Payload for DDoS via File Cloning
In this proof-of-concept, a Python payload is injected into an ONNX modelâ€™s metadata_props. The payload is Base64-encoded and embedded under the "run" key.

# ğŸ’£ Behavior Upon Execution:
When executed (via exec()), the payload:

1. Creates 10 copies of the infected model using shutil.copyfile().
2. Writes files named copy_0.onnx to copy_9.onnx.
3. Repeats the I/O operation, causing disk consumption and CPU load.
4. Although harmless in appearance, when done repeatedly or at scale, this becomes a Denial of Service (DoS) vector.

# ğŸ”¬ Attack Flow
1. Payload Injection into Model
2. Payload Triggered on Load

# ğŸ§ª Test Results
Upon loading:
  - Ten ONNX file clones are written to disk.
  - No warnings or alerts are triggered by onnx.load().
  - Resource usage spikes momentarily (disk I/O and CPU).
When deployed at scale (e.g., multiple users loading the model in parallel), this results in:
  - Disk exhaustion
  - Performance degradation
  - Potential system instability

<img width="626" height="396" alt="image" src="https://github.com/user-attachments/assets/21fab848-f54e-404b-babc-0585d88a4072" />


# â˜ ï¸ Real-World Impact
# ğŸ”„ Distributed Denial of Service (DDoS)
If the model is distributed via public platforms (e.g., Hugging Face, GitHub) and integrated into automated pipelines, this small-scale clone script can amplify across many machines, leading to a distributed attack.

# ğŸ’¡ Variants
1. Cloning thousands of files recursively.
2. Creating infinite loops or massive memory buffers.
3. Recursive payload execution (multi-layered propagation).

# ğŸ›¡ï¸ Mitigation & Defense Strategies
1. âŒ Never Execute Model Metadata
Avoid exec()/eval() on metadata fields at all costs. Treat metadata as non-executable strings.

# 2. ğŸ” Metadata Auditing
Implement scanners to detect:
- Suspicious keywords: exec, import, os, shutil, base64, etc.
- Base64 strings with decode patterns.
- Abnormally large metadata fields.

# 3. ğŸ§ª Model Sandbox Execution
Use containerized environments (e.g., Docker) with strict resource limits for testing model behavior.

# 4. ğŸ” Use Trusted Repositories
Only use ONNX models from official or verified sources. Treat user-uploaded models as potentially malicious.

# 5. ğŸ§° Secure Model Pipeline
Add:
  - Metadata sanitization tools.
  - Digital signature validation.
  - Structural validation before inference deployment.

# âš ï¸ Disclaimer
This repository is intended for educational and research purposes only.
The author disclaims all liability for any misuse of the code or technique.
Do not use this method in real-world environments or production systems.






      
